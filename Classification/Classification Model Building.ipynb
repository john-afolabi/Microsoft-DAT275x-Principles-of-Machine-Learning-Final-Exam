{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import feature_selection as fs\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as sklm\n",
    "import scipy.stats as ss\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16404 entries, 0 to 16403\n",
      "Data columns (total 11 columns):\n",
      "CustomerID           16404 non-null int64\n",
      "CountryRegionName    16404 non-null object\n",
      "Education            16404 non-null object\n",
      "Occupation           16404 non-null object\n",
      "Gender               16404 non-null object\n",
      "MaritalStatus        16404 non-null object\n",
      "NumberCarsOwned      16404 non-null int64\n",
      "TotalChildren        16404 non-null int64\n",
      "BikeBuyer            16404 non-null int64\n",
      "AgeRange             16404 non-null object\n",
      "log_YearlyIncome     16404 non-null float64\n",
      "dtypes: float64(1), int64(4), object(6)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Class_BikeBuyer.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(df['BikeBuyer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_string(cat_features):\n",
    "    ## First encode the strings to numeric categories\n",
    "    enc = preprocessing.LabelEncoder()\n",
    "    enc.fit(cat_features)\n",
    "    enc_cat_features = enc.transform(cat_features)\n",
    "    ## Now, apply one hot encoding\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    encoded = ohe.fit(enc_cat_features.reshape(-1,1))\n",
    "    return encoded.transform(enc_cat_features.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16404, 24)\n",
      "[[1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['Education', 'Occupation', 'Gender', 'MaritalStatus', 'AgeRange']\n",
    "Features = encode_string(df['CountryRegionName'])\n",
    "for col in categorical_columns:\n",
    "    temp = encode_string(df[col])\n",
    "    Features = np.concatenate([Features, temp], axis = 1)\n",
    "\n",
    "print(Features.shape)\n",
    "print(Features[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16404, 27)\n",
      "[[ 1.          0.          0.          0.          0.          0.\n",
      "   1.          0.          0.          0.          0.          0.\n",
      "   0.          0.          1.          0.          0.          1.\n",
      "   1.          0.          1.          0.          0.          0.\n",
      "   0.          2.         11.83462483]\n",
      " [ 1.          0.          0.          0.          0.          0.\n",
      "   1.          0.          0.          0.          0.          0.\n",
      "   0.          0.          1.          0.          0.          1.\n",
      "   0.          1.          1.          0.          0.          0.\n",
      "   1.          3.         11.52427086]]\n"
     ]
    }
   ],
   "source": [
    "Features = np.concatenate([Features, np.array(df[['NumberCarsOwned', \n",
    "                            'TotalChildren', 'log_YearlyIncome']])], axis = 1)\n",
    "print(Features.shape)\n",
    "print(Features[:2, :]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3280\n"
     ]
    }
   ],
   "source": [
    "indx = range(Features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = int(0.2*df.shape[0]))\n",
    "print(int(0.2*df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Features[indx[0],:]\n",
    "y_train = np.ravel(labels[indx[0]])\n",
    "X_test = Features[indx[1],:]\n",
    "y_test = np.ravel(labels[indx[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "        -0.59156479, -0.34454427],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "        -1.18630175, -0.36126677]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train[:,25:])\n",
    "X_train[:,25:] = scaler.transform(X_train[:,25:])\n",
    "X_test[:,25:] = scaler.transform(X_test[:,25:])\n",
    "X_train[:2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_mod = linear_model.LogisticRegression() \n",
    "logistic_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.82614232 0.17385768]\n",
      " [0.69827008 0.30172992]\n",
      " [0.50150094 0.49849906]\n",
      " [0.21193585 0.78806415]\n",
      " [0.82081826 0.17918174]\n",
      " [0.97602285 0.02397715]\n",
      " [0.78776119 0.21223881]\n",
      " [0.26786569 0.73213431]\n",
      " [0.93869988 0.06130012]\n",
      " [0.97239176 0.02760824]\n",
      " [0.89678132 0.10321868]\n",
      " [0.79707396 0.20292604]\n",
      " [0.88067048 0.11932952]\n",
      " [0.54902493 0.45097507]\n",
      " [0.63847287 0.36152713]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = logistic_mod.predict_proba(X_test)\n",
    "print(probabilities[:15,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 1 0 1 1 0 0 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "scores = score_model(probabilities, 0.5)\n",
    "print(np.array(scores[:15]))\n",
    "print(y_test[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive      1890               278\n",
      "Actual negative       524               588\n",
      "\n",
      "Accuracy  0.76\n",
      " \n",
      "           Positive      Negative\n",
      "Num case     2168          1112\n",
      "Precision    0.78          0.68\n",
      "Recall       0.87          0.53\n",
      "F1           0.82          0.59\n"
     ]
    }
   ],
   "source": [
    "def print_metrics(labels, scores):\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy  %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d'   % metrics[3][0] + '        %6d'   % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "print_metrics(y_test, scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(logistic_mod, open('classification_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
